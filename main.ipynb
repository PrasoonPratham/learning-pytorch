{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "class ToTe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(training_data, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_dl = DataLoader(test_data, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (dense1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (dense2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (dense3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Everthing in pytorch is a module, custom layers are modules, and Models too.\n",
    "# The nn.Sequential is a module that contains other modules.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_neurons, output_neurons):\n",
    "        super().__init__()\n",
    "\n",
    "        # Flatten 1.\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Dense 1\n",
    "        self.dense1 = nn.Linear(input_neurons, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Dense 2\n",
    "        self.dense2 = nn.Linear(256, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Dropout 0.2\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # Dense 3\n",
    "        self.dense3 = nn.Linear(128, output_neurons)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.dense2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize the net\n",
    "net = Net(28*28, 10)\n",
    "\n",
    "# Move to GPU\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (dense1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (dense2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (dense3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for idx, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"Epoch: {idx}/{len(dataloader)} Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, criterion):\n",
    "    model.eval()  # -> Eval mode\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, pred_idx = torch.max(pred, dim=1)\n",
    "            total_correct += torch.sum(pred_idx == y).item()\n",
    "\n",
    "    return total_loss / len(dataloaderect / len(dataloader)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/938 Loss: 2.3100764751434326\n",
      "Epoch: 10/938 Loss: 1.7960045337677002\n",
      "Epoch: 20/938 Loss: 1.2295677661895752\n",
      "Epoch: 30/938 Loss: 1.1003856658935547\n",
      "Epoch: 40/938 Loss: 0.9090185165405273\n",
      "Epoch: 50/938 Loss: 0.6407350897789001\n",
      "Epoch: 60/938 Loss: 0.9122637510299683\n",
      "Epoch: 70/938 Loss: 0.8925707936286926\n",
      "Epoch: 80/938 Loss: 0.7210111021995544\n",
      "Epoch: 90/938 Loss: 0.7114337086677551\n",
      "Epoch: 100/938 Loss: 0.7569505572319031\n",
      "Epoch: 110/938 Loss: 0.6603401899337769\n",
      "Epoch: 120/938 Loss: 0.6825844645500183\n",
      "Epoch: 130/938 Loss: 0.5834201574325562\n",
      "Epoch: 140/938 Loss: 0.6621996760368347\n",
      "Epoch: 150/938 Loss: 0.6589096188545227\n",
      "Epoch: 160/938 Loss: 0.6676016449928284\n",
      "Epoch: 170/938 Loss: 0.6308636665344238\n",
      "Epoch: 180/938 Loss: 0.5597556829452515\n",
      "Epoch: 190/938 Loss: 0.5062947273254395\n",
      "Epoch: 200/938 Loss: 0.8088880777359009\n",
      "Epoch: 210/938 Loss: 0.3685842752456665\n",
      "Epoch: 220/938 Loss: 0.731110692024231\n",
      "Epoch: 230/938 Loss: 0.5051828622817993\n",
      "Epoch: 240/938 Loss: 0.6201303005218506\n",
      "Epoch: 250/938 Loss: 0.4999483525753021\n",
      "Epoch: 260/938 Loss: 0.49295109510421753\n",
      "Epoch: 270/938 Loss: 0.5709702372550964\n",
      "Epoch: 280/938 Loss: 0.5764901041984558\n",
      "Epoch: 290/938 Loss: 0.5207639336585999\n",
      "Epoch: 300/938 Loss: 0.6283713579177856\n",
      "Epoch: 310/938 Loss: 0.40652281045913696\n",
      "Epoch: 320/938 Loss: 0.4252682626247406\n",
      "Epoch: 330/938 Loss: 0.6201152801513672\n",
      "Epoch: 340/938 Loss: 0.4327335059642792\n",
      "Epoch: 350/938 Loss: 0.5951432585716248\n",
      "Epoch: 360/938 Loss: 0.4889153838157654\n",
      "Epoch: 370/938 Loss: 0.46680212020874023\n",
      "Epoch: 380/938 Loss: 0.805939257144928\n",
      "Epoch: 390/938 Loss: 0.37434595823287964\n",
      "Epoch: 400/938 Loss: 0.4318876266479492\n",
      "Epoch: 410/938 Loss: 0.2820783257484436\n",
      "Epoch: 420/938 Loss: 0.545842170715332\n",
      "Epoch: 430/938 Loss: 0.6805699467658997\n",
      "Epoch: 440/938 Loss: 0.45519575476646423\n",
      "Epoch: 450/938 Loss: 0.39024844765663147\n",
      "Epoch: 460/938 Loss: 0.5846214890480042\n",
      "Epoch: 470/938 Loss: 0.3312077522277832\n",
      "Epoch: 480/938 Loss: 0.4320448040962219\n",
      "Epoch: 490/938 Loss: 0.5646637678146362\n",
      "Epoch: 500/938 Loss: 0.35931262373924255\n",
      "Epoch: 510/938 Loss: 0.51630038022995\n",
      "Epoch: 520/938 Loss: 0.47282788157463074\n",
      "Epoch: 530/938 Loss: 0.6009337902069092\n",
      "Epoch: 540/938 Loss: 0.2831341326236725\n",
      "Epoch: 550/938 Loss: 0.4270132780075073\n",
      "Epoch: 560/938 Loss: 0.25397342443466187\n",
      "Epoch: 570/938 Loss: 0.4207175672054291\n",
      "Epoch: 580/938 Loss: 0.43940651416778564\n",
      "Epoch: 590/938 Loss: 0.2614212930202484\n",
      "Epoch: 600/938 Loss: 0.541222870349884\n",
      "Epoch: 610/938 Loss: 0.2922724187374115\n",
      "Epoch: 620/938 Loss: 0.46261999011039734\n",
      "Epoch: 630/938 Loss: 0.43870142102241516\n",
      "Epoch: 640/938 Loss: 0.5634655952453613\n",
      "Epoch: 650/938 Loss: 0.37876445055007935\n",
      "Epoch: 660/938 Loss: 0.501147985458374\n",
      "Epoch: 670/938 Loss: 0.3704555034637451\n",
      "Epoch: 680/938 Loss: 0.5652469992637634\n",
      "Epoch: 690/938 Loss: 0.395340234041214\n",
      "Epoch: 700/938 Loss: 0.4277493953704834\n",
      "Epoch: 710/938 Loss: 0.3736456632614136\n",
      "Epoch: 720/938 Loss: 0.4915924668312073\n",
      "Epoch: 730/938 Loss: 0.47094783186912537\n",
      "Epoch: 740/938 Loss: 0.39897459745407104\n",
      "Epoch: 750/938 Loss: 0.42178022861480713\n",
      "Epoch: 760/938 Loss: 0.547532320022583\n",
      "Epoch: 770/938 Loss: 0.4415307939052582\n",
      "Epoch: 780/938 Loss: 0.5938400626182556\n",
      "Epoch: 790/938 Loss: 0.49863457679748535\n",
      "Epoch: 800/938 Loss: 0.3528636693954468\n",
      "Epoch: 810/938 Loss: 0.5149734616279602\n",
      "Epoch: 820/938 Loss: 0.46601033210754395\n",
      "Epoch: 830/938 Loss: 0.4065294861793518\n",
      "Epoch: 840/938 Loss: 0.45352521538734436\n",
      "Epoch: 850/938 Loss: 0.5058609843254089\n",
      "Epoch: 860/938 Loss: 0.2317814826965332\n",
      "Epoch: 870/938 Loss: 0.4220062494277954\n",
      "Epoch: 880/938 Loss: 0.5912563800811768\n",
      "Epoch: 890/938 Loss: 0.41269803047180176\n",
      "Epoch: 900/938 Loss: 0.6427281498908997\n",
      "Epoch: 910/938 Loss: 0.35900577902793884\n",
      "Epoch: 920/938 Loss: 0.46002984046936035\n",
      "Epoch: 930/938 Loss: 0.462765097618103\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train(train_dl, net, criterion, optimizer)\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_acc = test(test_dl, net, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.41618773493037864 Test Accuracy: 54.1656050955414\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Loss: {test_loss} Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "# Enter eval mode\n",
    "net.eval()\n",
    "\n",
    "# Get data\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "\n",
    "x = x.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = net(x)\n",
    "\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e32cd702cea00fdab1c4da36b0135a934572a11d71a044abf6d4ffc2057e8a1e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pt': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
